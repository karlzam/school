{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a3208f-7e35-4f80-9234-82763f1bbf8d",
   "metadata": {},
   "source": [
    "# Phys555 Assignment 2 Question 2\n",
    "Karlee Zammit - V00823093\n",
    "\n",
    "Q2 - Use  the Q1 regression data set for the following:\n",
    "A) Use the linear regression model in the module 'Class04-Jan19.' Change the hyperparameters to get the best predictions. Explain the details and discuss the accuracy/performance of the model (i.e., associated plots and metrics). \n",
    "B) Do the same with KNN regression. What is the best K for your data? Which model (A or B) is more accurate (higher performance)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4ace6-7295-4614-9772-4a7b3701b9a4",
   "metadata": {},
   "source": [
    "# Introduction: Linear Regression and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b8ec5e-f722-4f48-9bfd-4acf2cb989ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from pandas.plotting import scatter_matrix    \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import sys\n",
    "from scipy.interpolate import interp1d\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37785e-5866-48bc-ba60-9b7588fd1a33",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5735b5-8426-4c05-8b35-dca956c7a49b",
   "metadata": {},
   "source": [
    "## Linear Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f82639-60c4-4071-8c37-d94405405733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same linear regression model as in Q2 so the results are comparable, for the data keeping only n_components \n",
    "def linear_regression(X_tr, X_va, Y_tr, Y_va, xlim, ylim, textx, texty, text2x, text2y):\n",
    "    reg = linear_model.SGDRegressor(loss='squared_error', penalty='L2', alpha=0.001,\n",
    "                                   max_iter=2000, eta0=.001, tol=0.0001, learning_rate='constant', n_iter_no_change=5)\n",
    "\n",
    "    # Fit the model on the PCA data\n",
    "    reg.fit(X_tr,Y_tr)  # fit the model with training set\n",
    "\n",
    "    #'predictions for training and validation sets'\n",
    "    Y_tr_pred = reg.predict(X_tr)  \n",
    "    Y_va_pred = reg.predict(X_va)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(Y_tr,Y_tr_pred,'ob')\n",
    "    plt.plot(Y_va,Y_va_pred,'.r')\n",
    "\n",
    "    plt.plot(np.arange(xlim,ylim,.1),  np.arange(xlim,ylim,.1),'-k')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Predicted X')\n",
    "    plt.legend(['Training', 'Validation'], loc='best')\n",
    "    # plt.xlim([0,2])\n",
    "    # plt.ylim([0,2])\n",
    "\n",
    "    #Statistical information regarding training and validation predictions\n",
    "    mu_lr = np.mean(Y_tr-Y_tr_pred)\n",
    "    median_lr = np.median(Y_tr-Y_tr_pred)\n",
    "    sigma_lr = np.std(Y_tr-Y_tr_pred)\n",
    "\n",
    "    muv_lr = np.mean(Y_va-Y_va_pred)\n",
    "    medianv_lr = np.median(Y_va-Y_va_pred)\n",
    "    sigmav_lr = np.std(Y_va-Y_va_pred)\n",
    "\n",
    "    textstr = '$\\mu=%.4f$\\n$\\mathrm{med}=%.4f$\\n$\\sigma=%.4f$'%(mu_lr, median_lr, sigma_lr)\n",
    "    textstrv = '$\\mu=%.4f$\\n$\\mathrm{med}=%.4f$\\n$\\sigma=%.4f$'%(muv_lr, medianv_lr, sigmav_lr)\n",
    "\n",
    "    plt.text(textx,texty,textstr, color='b',fontsize=15)\n",
    "    plt.text(text2x,text2y,textstrv, color='r',fontsize=15)\n",
    "    plt.title('Linear Regression')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.hist(Y_tr_pred-Y_tr,20,color='b',histtype='step',density=True,label='training')\n",
    "    plt.hist(Y_va_pred-Y_va,20,color='r',histtype='step',density=True,label='validation')\n",
    "    plt.xlabel('Predicted - real')\n",
    "    plt.ylabel('Probability (density)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(3)\n",
    "    plt.scatter(Y_tr,Y_tr_pred-Y_tr,label='training',color='b',alpha=.3)\n",
    "    plt.scatter(Y_va,Y_va_pred-Y_va,label='test',color='r',alpha=.3)\n",
    "    plt.xlabel('Y (real)')\n",
    "    plt.ylabel('Y (predicted) - Y (real)')\n",
    "    plt.plot([xlim,ylim],[0,0],'y')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0c378-f4fe-46f8-98a5-d1b494e70942",
   "metadata": {},
   "source": [
    "## KNN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e467e5f9-f977-4b5f-9c9e-c494b0a93a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour(X_tr, X_va, Y_tr, Y_va, xlim, ylim, textx, texty, text2x, text2y):    \n",
    "    KNN = KNeighborsRegressor(n_neighbors=5, weights='uniform')  # set the hyperparameters\n",
    "    KNN.fit(X_tr,Y_tr)  # train it\n",
    "\n",
    "    #'predictions for training and validation sets'\n",
    "    Y_tr_pred= KNN.predict(X_tr)  \n",
    "    Y_va_pred= KNN.predict(X_va)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(Y_tr,Y_tr_pred,'ob')\n",
    "    plt.plot(Y_va,Y_va_pred,'.r')\n",
    "\n",
    "    plt.plot(np.arange(xlim,ylim,.1),  np.arange(xlim,ylim,.1),'-k')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Predicted X')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    #Statistical information regarding training and validation predictions\n",
    "    mu = np.mean(Y_tr-Y_tr_pred)\n",
    "    median = np.median(Y_tr-Y_tr_pred)\n",
    "    sigma = np.std(Y_tr-Y_tr_pred)\n",
    "\n",
    "    muv = np.mean(Y_va-Y_va_pred)\n",
    "    medianv = np.median(Y_va-Y_va_pred)\n",
    "    sigmav = np.std(Y_va-Y_va_pred)\n",
    "\n",
    "    textstr = '$\\mu=%.4f$\\n$\\mathrm{med}=%.4f$\\n$\\sigma=%.4f$'%(mu, median, sigma)\n",
    "    textstrv = '$\\mu=%.4f$\\n$\\mathrm{med}=%.4f$\\n$\\sigma=%.4f$'%(muv, medianv, sigmav)\n",
    "\n",
    "    plt.text(textx,texty,textstr, color='b',fontsize=15)\n",
    "    plt.text(text2x,text2y,textstrv, color='r',fontsize=15)\n",
    "    plt.title('KNN Regression')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.hist(Y_tr_pred-Y_tr,20,color='b',histtype='step',density=True,label='training')\n",
    "    plt.hist(Y_va_pred-Y_va,20,color='r',histtype='step',density=True,label='validation')\n",
    "    plt.xlabel('Predicted - real')\n",
    "    plt.ylabel('Probability (density)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(3)\n",
    "    plt.scatter(Y_tr,Y_tr_pred-Y_tr,label='training',color='b',alpha=.3)\n",
    "    plt.scatter(Y_va,Y_va_pred-Y_va,label='test',color='r',alpha=.3)\n",
    "    plt.xlabel('Y (real)')\n",
    "    plt.ylabel('Y (predicted) - Y (real)')\n",
    "    plt.plot([xlim,ylim],[0,0],'y')\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee24b71-4cb2-4d2c-b2c9-097d2e992f60",
   "metadata": {},
   "source": [
    "## Split and Normalize Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9d6d7a-65c6-400e-9357-dba69211c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,Y):\n",
    "    # Split the input and target data into test and train, with 75% of the data going to training, and 25% of the data going to testing\n",
    "    X_tr, X_va, Y_tr, Y_va = train_test_split(X,Y.values.ravel(),test_size=0.25)\n",
    "\n",
    "    # Print the shape of the split data\n",
    "    print ('training set == ',np.shape(X_tr),np.shape(Y_tr),',, validation set == ', np.shape(X_va),np.shape(Y_va))\n",
    "    \n",
    "    # Normalize the data, as was done in Q2\n",
    "    scaler_S= StandardScaler().fit(X_tr)  # line #2\n",
    "    X_tr_Norm= scaler_S.transform(X_tr) # line # 3\n",
    "    X_va_Norm= scaler_S.transform(X_va)  # Line #4\n",
    "    \n",
    "    n_column = 2\n",
    "\n",
    "    # Plot a figure of the normalized training and validation set to ensure they represent the same distribution and spread\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(X_tr_Norm[:,n_column])\n",
    "    plt.title('Training set')\n",
    "    plt.ylabel('N')\n",
    "    plt.xlabel(\"X\"+str(n_column))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(X_va_Norm[:,n_column])\n",
    "    plt.title('Validation set')\n",
    "    plt.ylabel('N')\n",
    "    plt.xlabel(\"X\"+str(n_column))\n",
    "    \n",
    "    return X_tr_Norm, X_va_Norm, Y_tr, Y_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bffaf-1ae3-4bcd-9c8d-e323d222cc3f",
   "metadata": {},
   "source": [
    "# Sachs Harbour: Linear Regression and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe570044-c0b2-48d7-b62a-75ecf1fc5d80",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Ambient Sound Data Sachs Harbour 2015-2016.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4328\\2670043850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_SH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Ambient Sound Data Sachs Harbour 2015-2016.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_SH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_SH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Deployment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Day'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Hour'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DateTime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_SH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_SH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Set temperature as the target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\phys555\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\phys555\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\phys555\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 ext = inspect_excel_format(\n\u001b[1;32m-> 1192\u001b[1;33m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1193\u001b[0m                 )\n\u001b[0;32m   1194\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\phys555\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m     with get_handle(\n\u001b[1;32m-> 1071\u001b[1;33m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     ) as handle:\n\u001b[0;32m   1073\u001b[0m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\phys555\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Ambient Sound Data Sachs Harbour 2015-2016.xlsx'"
     ]
    }
   ],
   "source": [
    "df_SH = pd.read_excel('Ambient Sound Data Sachs Harbour 2015-2016.xlsx')\n",
    "df_SH = df_SH.drop(['Deployment', 'Year', 'Month', 'Day', 'Hour', 'DateTime', 'Ice'], axis=1)\n",
    "df_SH=df_SH.dropna(axis=0)\n",
    "\n",
    "# Set temperature as the target variable\n",
    "var = ['Temperature']\n",
    "\n",
    "# Drop temperature out of the weather data, and set it as X\n",
    "X = df_SH.loc[:,df_SH.columns.drop(var)]\n",
    "print(X.columns)\n",
    "\n",
    "# Set the target (Y) to be temperature\n",
    "Y = df_SH[var].copy()\n",
    "print(Y.columns)\n",
    "\n",
    "X_tr_Norm, X_va_Norm, Y_tr, Y_va = split_data(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ceb6e0-af92-4253-a9c9-ee6a1efbddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression(X_tr_Norm, X_va_Norm, Y_tr, Y_va, -40, 30, 45, 10, 45, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54df63-5a7c-45b3-80c9-b46d4efc9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbour(X_tr_Norm, X_va_Norm, Y_tr, Y_va, -40, 30, 45, 10, 45, -10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfaef8b-2047-4a48-8f4d-29036472f829",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431205b0-01a5-42b8-b15e-39f4e31bfb19",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Bishop, C. M. (2006). Pattern recognition and machine learning. In Pattern recognition and machine learning. Springer.\n",
    "\n",
    "https://www.kaggle.com/datasets/budincsevity/szeged-weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f3ea77-388e-4705-b57b-3c8b35402946",
   "metadata": {},
   "source": [
    "# Appendix: Extra Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fe025-d20a-41a4-bdea-4b0480b57a69",
   "metadata": {},
   "source": [
    "## Szeged Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7d35f-1c54-4e3f-b5db-e5341b2fd910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv data and perform the same data mining steps as was done in question 1\n",
    "weather = pd.read_csv(r'weatherHistory.csv', delimiter=',')\n",
    "weather=weather.dropna(axis=0)\n",
    "weather = weather.drop(['Formatted Date', 'Summary', 'Daily Summary', 'Precip Type', 'Loud Cover', 'Visibility (km)'], axis=1)\n",
    "weather_mined = weather.loc[ weather['Pressure (millibars)'] != 0]\n",
    "weather_mined = weather_mined.loc[weather_mined['Humidity'] != 0]\n",
    "weather_mined.hist(figsize=(10, 8), bins=30, edgecolor=\"black\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3713f4-f661-4d2f-8cbb-fa17f02999e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set temperature as the target variable\n",
    "var = ['Temperature (C)']\n",
    "\n",
    "# Drop temperature out of the weather data, and set it as X\n",
    "X = weather_mined.loc[:, weather_mined.columns.drop(var)]\n",
    "print(X.columns)\n",
    "\n",
    "# Set the target (Y) to be temperature\n",
    "Y = weather_mined[var].copy()\n",
    "print(Y.columns)\n",
    "\n",
    "X_tr_Norm, X_va_Norm, Y_tr, Y_va = split_data(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6036ce7-8a67-4e9a-97db-e25649f5e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression(X_tr_Norm, X_va_Norm, Y_tr, Y_va, -20, 40, 45, 10, 45, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f709e7d-b651-4abf-a724-ec384f6748ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbour(X_tr_Norm, X_va_Norm, Y_tr, Y_va, -20, 40, 45, 10, 45, -10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270cdb3-86ba-4ebe-a35f-e9aac14de498",
   "metadata": {},
   "source": [
    "## Beans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb37bf-36d1-4f42-8742-6fbc3f97a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = pd.read_excel(r'Dry_Bean_Dataset.xlsx')\n",
    "beans = beans.drop(['Class'], axis=1)\n",
    "\n",
    "# Set temperature as the target variable\n",
    "var = ['Perimeter']\n",
    "\n",
    "# Drop temperature out of the weather data, and set it as X\n",
    "X = beans.loc[:, beans.columns.drop(var)]\n",
    "print(X.columns)\n",
    "\n",
    "# Set the target (Y) to be temperature\n",
    "Y = beans[var].copy()\n",
    "print(Y.columns)\n",
    "\n",
    "X_tr_Norm, X_va_Norm, Y_tr, Y_va = split_data(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90bedb8-80cb-4c6b-a113-304c138299ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression(X_tr_Norm, X_va_Norm, Y_tr, Y_va, 450, 2000, 2100, 800, 2100, 1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1148f-a373-45e6-b70b-65db7198e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbour(X_tr_Norm, X_va_Norm, Y_tr, Y_va, 450, 2000, 2100, 800, 2100, 1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93aaa9d-18df-45f8-80f7-f918877d64ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phys555",
   "language": "python",
   "name": "phys555"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
